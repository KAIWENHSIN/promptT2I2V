import streamlit as st
from deep_translator import GoogleTranslator
import google.generativeai as genai

# 1. é é¢é…ç½® (ç½®ä¸­)
st.set_page_config(page_title="T2I2V Studio Pro", page_icon="ğŸ¬", layout="centered")

# 2. åˆå§‹åŒ– API (è§£æ±º 404 æ¨¡å‹æ‰¾ä¸åˆ°çš„å•é¡Œ)
if "GEMINI_API_KEY" in st.secrets:
    try:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        # æ”¹ç”¨é€™ç¨®å¯«æ³•ä¾†ç›¸å®¹ä¸åŒç‰ˆæœ¬çš„ API
        model = genai.GenerativeModel('gemini-1.5-flash')
    except:
        model = None
else:
    st.error("âŒ å°šæœªåœ¨ Secrets ä¸­è¨­å®š GEMINI_API_KEY")
    model = None

translator = GoogleTranslator(source='auto', target='en')

# 3. åˆå§‹åŒ–å­˜å„²ç©ºé–“
if 'sub_en' not in st.session_state: st.session_state.sub_en = ""
if 'env_en' not in st.session_state: st.session_state.env_en = ""

def call_ai(text, part):
    if not model or not text: return ""
    try:
        # é€™æ˜¯æœ€ç©©å®šçš„ç”Ÿæˆå‘¼å«æ–¹å¼
        response = model.generate_content(f"Expand this {part} into a cinematic English prompt: {text}. Return ONLY the English text.")
        return response.text.strip()
    except Exception as e:
        return f"AI æš«æ™‚ç„¡æ³•å›æ‡‰ï¼ŒåŸå› ï¼š{str(e)}"

# 4. ä»‹é¢èˆ‡åŠŸèƒ½
st.title("ğŸ“½ï¸ T2I2V Studio Pro")

# æ”å½±åƒæ•¸
with st.expander("ğŸ¥ æ”å½±è¨­å®š", expanded=True):
    col1, col2 = st.columns(2)
    with col1:
        style = st.selectbox("é¢¨æ ¼", ["National Geographic", "Arri Alexa", "Kodak Portra"])
        lens = st.selectbox("ç„¦æ®µ", ["24mm Wide", "50mm Standard", "85mm Portrait"])
    with col2:
        angle = st.selectbox("è§’åº¦", ["Eye-level", "High angle", "Low angle"])
        move_map = {"Static": "static", "Pan": "pan", "Zoom": "zoom", "Orbit": "orbit"}
        move_key = st.selectbox("é‹é¡", list(move_map.keys()))

st.divider()

# è¼¸å…¥å€
u_kw = st.text_area("âœï¸ ä¸»é«”å‹•ä½œ (ä¸­æ–‡)", height=100)
if st.button("âœ¨ ä½¿ç”¨ AI æ“´å……ä¸»é«”"):
    st.session_state.sub_en = call_ai(u_kw, "subject action")
if st.session_state.sub_en:
    st.info(f"AI å»ºè­°å…§å®¹ï¼š{st.session_state.sub_en}")

u_env = st.text_input("ğŸŒ åœ°é»ç’°å¢ƒ (ä¸­æ–‡)")
if st.button("âœ¨ ä½¿ç”¨ AI æ“´å……ç’°å¢ƒ"):
    st.session_state.env_en = call_ai(u_env, "environment")
if st.session_state.env_en:
    st.info(f"AI å»ºè­°å…§å®¹ï¼š{st.session_state.env_en}")

st.divider()

# ç”Ÿæˆçµæœ
if st.button("ğŸš€ ç”Ÿæˆæç¤ºè©çµ„", type="primary"):
    if u_kw:
        final_sub = st.session_state.sub_en if st.session_state.sub_en else translator.translate(u_kw)
        final_env = st.session_state.env_en if st.session_state.env_en else translator.translate(u_env)
        
        t2i = f"RAW photo, {final_env}, {angle}, {lens}, {final_sub}, {style} --ar 16:9"
        i2v = f"Mostly {move_map[move_key]}, {final_sub} continues action."
        
        st.subheader("âœ… ç”Ÿæˆçµæœ")
        st.code(f"Step 1 (åº•åœ–):\n{t2i}")
        st.code(f"Step 2 (å½±ç‰‡):\n{i2v}")
    else:
        st.error("è«‹è¼¸å…¥å…§å®¹")
