import streamlit as st
from deep_translator import GoogleTranslator
import google.generativeai as genai

# 1. é é¢é…ç½®èˆ‡é«˜ç´šæ„Ÿ CSS (ç½®ä¸­å„ªåŒ–)
st.set_page_config(page_title="T2I2V Studio Pro", page_icon="ğŸ¬", layout="centered")

st.markdown("""
    <style>
    /* å…¨åŸŸèƒŒæ™¯èˆ‡ç½®ä¸­é™åˆ¶ */
    .main { background-color: #050505; color: #e0e0e0; }
    .block-container { padding-top: 2rem; max-width: 800px !important; }
    
    /* è¼¸å…¥æ¡†èˆ‡æ–‡å­—å€æ¨£å¼ */
    .stTextInput>div>div>input, .stTextArea>div>div>textarea { 
        background-color: #1a1a1a !important; color: white !important; 
        border-radius: 12px !important; border: 1px solid #333 !important;
        transition: 0.3s;
    }
    .stTextInput>div>div>input:focus, .stTextArea>div>div>textarea:focus {
        border-color: #4f46e5 !important; box-shadow: 0 0 10px rgba(79, 70, 229, 0.3);
    }
    
    /* æŒ‰éˆ•æ¨£å¼å„ªåŒ– */
    .stButton>button { 
        border-radius: 12px; height: 3.5em; background-color: #4f46e5; 
        color: white; border: none; width: 100%; font-weight: bold;
        letter-spacing: 1px;
    }
    .stButton>button:hover { 
        background-color: #6366f1; transform: translateY(-2px); 
        box-shadow: 0 5px 15px rgba(79, 70, 229, 0.4);
    }
    
    /* AI æ“´å……çµæœå€å¡Š */
    .enhance-res { 
        background-color: #0e1117; padding: 15px; border-radius: 12px; 
        border-left: 4px solid #818cf8; margin: 15px 0; 
        font-style: italic; color: #cbd5e1; font-size: 0.95em;
    }
    
    /* çµæœé¡¯ç¤ºå¡ç‰‡ */
    .result-card { 
        background-color: #111; padding: 25px; border-radius: 18px; 
        border: 1px solid #222; border-top: 4px solid #4f46e5; 
        margin-top: 25px; box-shadow: 0 10px 30px rgba(0,0,0,0.5);
    }
    code { color: #818cf8 !important; font-size: 1.1em !important; background-color: #1a1a1a !important; padding: 5px !important; }
    </style>
    """, unsafe_allow_html=True)

# 2. åˆå§‹åŒ– API
if "GEMINI_API_KEY" in st.secrets:
    try:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        # ä½¿ç”¨æ¨™æº–æ¨¡å‹åç¨±ï¼Œè§£æ±º 404 å ±éŒ¯
        model = genai.GenerativeModel('gemini-1.5-flash')
    except Exception as e:
        st.error(f"API è¨­å®šå¤±æ•—: {str(e)}")
        model = None
else:
    st.error("âŒ å°šæœªåœ¨ Streamlit Secrets ä¸­è¨­å®š GEMINI_API_KEY")
    model = None

translator = GoogleTranslator(source='auto', target='en')

# 3. åˆå§‹åŒ– Session State
if 'sub_en' not in st.session_state: st.session_state.sub_en = ""
if 'env_en' not in st.session_state: st.session_state.env_en = ""

def call_ai(text, part):
    if not model or not text: return ""
    try:
        # ç§»é™¤å¯èƒ½å°è‡´ API å ±éŒ¯çš„ç‰¹æ®Šå­—å…ƒ
        clean_text = text.replace('\n', ' ').strip()
        prompt = f"You are a cinematic prompt expert. Expand the following {part} into a detailed, high-fidelity English description for AI video generation. Return ONLY the expanded English text.\nContent: {clean_text}"
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        return f"AI Error: {str(e)}"

# 4. ä¸»ç•«é¢ä»‹é¢
st.title("ğŸ“½ï¸ T2I2V Studio Pro")
st.markdown("##### å°ˆæ¥­å¯¦æ‹æç¤ºè©å·¥ä½œç«™")
st.caption("æ”¯æ´ Gemini AI è‡ªå‹•æ“´å……èˆ‡å…¨å¥—å¯¦æ‹é‹é¡é‚è¼¯")

# --- æ”å½±åƒæ•¸è¨­å®š ---
with st.expander("ğŸ¥ æ”å½±æ©Ÿèˆ‡é‹é¡è¨­å®š (Camera Settings)", expanded=True):
    col_s1, col_s2 = st.columns(2)
    with col_s1:
        style = st.selectbox("å½±è¦–é¢¨æ ¼", ["National Geographic", "Kodak Portra 400", "Arri Alexa Cinematic", "IMAX 70mm", "Fashion Editorial"])
        lens = st.selectbox("ç„¦æ®µ", ["8mm Fisheye", "14mm Ultra-Wide", "24mm Wide", "35mm Classic", "50mm Standard", "85mm Portrait", "200mm Telephoto"])
    with col_s2:
        angle = st.selectbox("é¡ä½è§’åº¦", ["Eye-level shot", "High angle shot", "Low angle shot", "Dutch angle", "Front angle", "Over-the-shoulder"])
        # æ ¹æ“š image_3f56d4.png å®Œæ•´å°æ‡‰é‹é¡æ¸…å–®
        move_map = {
            "Static (éœæ…‹)": "static camera, no movement",
            "Handheld (æ‰‹æŒå¾®å‹•)": "subtle handheld micro-movement",
            "Zoom Out (ç¸®æ”¾-é )": "slow zoom out movement",
            "Zoom in (ç¸®æ”¾-è¿‘)": "slow zoom in movement",
            "Camera follows (è·Ÿé¡)": "camera follows the subject movement",
            "Pan left (å·¦æ©«ç§»æ–é¡)": "smooth pan left",
            "Pan right (å³æ©«ç§»æ–é¡)": "smooth pan right",
            "Tilt up (ä»°æ‹æ–é¡)": "slow tilt up",
            "Tilt down (ä¿¯æ‹æ–é¡)": "slow tilt down",
            "Orbit around (ç’°ç¹é‹é¡)": "360-degree orbit around subject",
            "Dolly In (æ¨å…¥é‹é¡)": "camera dollies in closer",
            "Dolly Out (æ‹‰å‡ºé‹é¡)": "camera dollies out away",
            "Dolly Left (å‘å·¦å¹³ç§»)": "camera dollies to the left",
            "Dolly Right (å‘å³å¹³ç§»)": "camera dollies to the right",
            "Jib up (æ–è‡‚ä¸Šå‡)": "jib up shot, rising",
            "Jib down (æ–è‡‚ä¸‹é™)": "jib down shot, lowering",
            "Drone shot (èˆªæ‹)": "high altitude drone sweeping",
            "360 roll (360åº¦ç¿»è½‰)": "cinematic 360-degree barrel roll"
        }
        move_key = st.selectbox("é‹é¡æ–¹å¼", list(move_map.keys()))

st.divider()

# --- ä½¿ç”¨è€…è¼¸å…¥å€åŸŸ ---
u_kw = st.text_area("âœï¸ ä¸»é«”å‹•ä½œ (ä¸­æ–‡)", placeholder="ä¾‹å¦‚ï¼šå¥³å­©åœ¨è‰åœ°ä¸Šå¥”è·‘", height=100)
if st.button("âœ¨ ä½¿ç”¨ AI æ“´å……ä¸»é«”ç´°ç¯€"):
    if u_kw:
        with st.spinner("AI æ­£åœ¨åˆ†æå‹•ä½œ..."):
            st.session_state.sub_en = call_ai(u_kw, "subject action")
    else: st.warning("è«‹å…ˆè¼¸å…¥ä¸»é«”å‹•ä½œ")

if st.session_state.sub_en:
    st.markdown(f'<div class="enhance-res"><b>AI Enhanced Subject:</b><br>{st.session_state.sub_en}</div>', unsafe_allow_html=True)

u_env = st.text_input("ğŸŒ åœ°é»èˆ‡å…‰å½± (ä¸­æ–‡)", placeholder="ä¾‹å¦‚ï¼šé»ƒæ˜ï¼Œé‡‘è‰²æŸ”å…‰")
if st.button("âœ¨ ä½¿ç”¨ AI æ“´å……ç’°å¢ƒç´°ç¯€"):
    if u_env:
        with st.spinner("AI æ­£åœ¨æ§‹å»ºå ´æ™¯..."):
            st.session_state.env_en = call_ai(u_env, "environment and lighting")
    else: st.warning("è«‹å…ˆè¼¸å…¥åœ°é»ç’°å¢ƒ")

if st.session_state.env_en:
    st.markdown(f'<div class="enhance-res"><b>AI Enhanced Environment:</b><br>{st.session_state.env_en}</div>', unsafe_allow_html=True)

st.divider()

# --- ç”Ÿæˆæœ€çµ‚æç¤ºè© ---
if st.button("ğŸš€ ç”Ÿæˆæœ€çµ‚é›™èªæç¤ºè©çµ„", type="primary"):
    if u_kw:
        with st.spinner("æ­£åœ¨ç¿»è­¯ä¸¦çµ±æ•´..."):
            # è‹¥ç„¡ AI æ“´å……çµæœå‰‡ä½¿ç”¨ç›´æ¥ç¿»è­¯
            final_sub = st.session_state.sub_en if st.session_state.sub_en else translator.translate(u_kw)
            final_env = st.session_state.env_en if st.session_state.env_en else translator.translate(u_env)
            
            neg = "--no flicker, no warping, no melting, no jitter, no text, no watermark, animation, cgi, 3d render"
            
            # Step 1: T2I Prompt
            t2i = f"RAW photo, {final_env}. {angle}, {lens}. {final_sub}. {style}, high-fidelity, documentary feel. {neg}"
            
            # Step 2: I2V Prompt
            i2v = f"Mostly {move_map[move_key]}. [Subject: {final_sub} continues action]. Realistic motion blur. {neg}"
            
            st.success("âœ… æç¤ºè©çµ„åˆå®Œæˆï¼")
            
            st.markdown('<div class="result-card">', unsafe_allow_html=True)
            st.markdown("#### Step 1: T2I (Kling/Midjourney/Luma) åº•åœ–ç”Ÿæˆ")
            st.code(t2i)
            st.markdown("#### Step 2: I2V (Runway/Kling) å½±ç‰‡å‹•æ…‹ç”Ÿæˆ")
            st.code(i2v)
            st.markdown('</div>', unsafe_allow_html=True)
            
            st.info("ğŸ’¡ å»ºè­°ï¼šè«‹å…ˆä½¿ç”¨ Step 1 ç”Ÿæˆé«˜å“è³ªåº•åœ–ï¼Œå†å°‡åœ–ä¸Šå‚³è‡³å½±ç‰‡æ¨¡å‹ä¸¦æ­é… Step 2 æç¤ºè©ã€‚")
    else:
        st.error("ä¸»é«”å‹•ä½œç‚ºå¿…å¡«é …")
